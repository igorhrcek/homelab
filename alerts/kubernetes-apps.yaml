---
groups:
  - name: kubernetes.apps.rules
    rules:
      - alert: KubePodCrashLooping
        annotations:
          summary: Pod is crash looping.
          description: >
            Pod `{{ $labels.namespace }}`/`{{ $labels.pod }}` (`{{ $labels.container }}`) is in waiting state (reason: "CrashLoopBackOff").
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
        expr: |
          max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
        for: "5m"
        labels:
          severity: warning

      - alert: KubePodCrashLooping
        annotations:
          summary: Pod is crash looping.
          description: >
            Pod `{{ $labels.namespace }}`/`{{ $labels.pod }}` (`{{ $labels.container }}`) is in waiting state (reason: "CrashLoopBackOff").
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
        expr: |
          max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
        for: "10m"
        labels:
          severity: critical

      - alert: KubePodNotReady
        annotations:
          summary: Pod has been in a non-ready state for more than 15 minutes.
          description: >
            Pod `{{ $labels.namespace }}`/`{{ $labels.pod }}` has been in a non-ready state for longer than 15 minutes.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
        expr: |
          sum by (namespace, pod, cluster) (
            max by(namespace, pod, cluster) (
              kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown|Failed"}
            ) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (
              1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
            )
          ) > 0
        for: "15m"
        labels:
          severity: warning

      - alert: KubeDeploymentGenerationMismatch
        annotations:
          summary: Deployment generation mismatch due to possible roll-back
          description: >
            Deployment generation for `{{ $labels.namespace }}`/`{{ $labels.deployment }}` does not match, this indicates that the Deployment has failed but has not been rolled back.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
        expr: |
          kube_deployment_status_observed_generation{job="kube-state-metrics"}
            !=
          kube_deployment_metadata_generation{job="kube-state-metrics"}
        for: "15m"
        labels:
          severity: warning

      - alert: KubeDeploymentReplicasMismatch
        annotations:
          description: >
            Deployment `{{ $labels.namespace }}`/`{{ $labels.deployment }}` has not matched the expected number of replicas for longer than 15 minutes.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          summary: Deployment has not matched the expected number of replicas.
        expr: |
          (
            kube_deployment_spec_replicas{job="kube-state-metrics"}
              >
            kube_deployment_status_replicas_available{job="kube-state-metrics"}
          ) and (
            changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[10m])
              ==
            0
          )
        for: "15m"
        labels:
          severity: warning

      - alert: KubeDeploymentRolloutStuck
        annotations:
          description: >
            Rollout of deployment `{{ $labels.namespace }}`/`{{ $labels.deployment }}` is not progressing for longer than 15 minutes.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentrolloutstuck"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: Deployment rollout is not progressing.
        expr: |
          kube_deployment_status_condition{condition="Progressing", status="false",job="kube-state-metrics"}
          != 0
        for: "15m"
        labels:
          severity: warning

      - alert: KubeStatefulSetReplicasMismatch
        annotations:
          description: >
            StatefulSet `{{ $labels.namespace }}`/`{{ $labels.statefulset }}` has not matched the expected number of replicas for longer than 15 minutes.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: StatefulSet has not matched the expected number of replicas.
        expr: |
          (
            kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
              !=
            kube_statefulset_status_replicas{job="kube-state-metrics"}
          ) and (
            changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[10m])
              ==
            0
          )
        for: "15m"
        labels:
          severity: warning

      - alert: KubeStatefulSetGenerationMismatch
        annotations:
          description: >
            StatefulSet generation for `{{ $labels.namespace }}`/`{{ $labels.statefulset }}` does not match, this indicates that the StatefulSet has failed but has not been rolled back.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: StatefulSet generation mismatch due to possible roll-back
        expr: |
          kube_statefulset_status_observed_generation{job="kube-state-metrics"}
            !=
          kube_statefulset_metadata_generation{job="kube-state-metrics"}
        for: "15m"
        labels:
          severity: warning

      - alert: KubeStatefulSetUpdateNotRolledOut
        annotations:
          description: >
            StatefulSet `{{ $labels.namespace }}`/`{{ $labels.statefulset }}` update has not been rolled out.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: StatefulSet update has not been rolled out.
        expr: |
          (
            max by(namespace, statefulset, job, cluster) (
              kube_statefulset_status_current_revision{job="kube-state-metrics"}
                unless
              kube_statefulset_status_update_revision{job="kube-state-metrics"}
            )
              *
            (
              kube_statefulset_replicas{job="kube-state-metrics"}
                !=
              kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
            )
          )  and (
            changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m])
              ==
            0
          )
        for: "15m"
        labels:
          severity: warning

      - alert: KubeDaemonSetRolloutStuck
        annotations:
          description: >
            DaemonSet `{{ $labels.namespace }}`/`{{ $labels.daemonset }}` has not finished or progressed for at least 15m.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: DaemonSet rollout is stuck.
        expr: |
          (
            (
              kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"}
              !=
              kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
            ) or (
              kube_daemonset_status_number_misscheduled{job="kube-state-metrics"}
              !=
              0
            ) or (
              kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}
              !=
              kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
            ) or (
              kube_daemonset_status_number_available{job="kube-state-metrics"}
              !=
              kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
            )
          ) and (
            changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}[5m])
              ==
            0
          )
        for: "15m"
        labels:
          severity: warning

      - alert: KubeContainerWaiting
        annotations:
          description: >
            `pod/{{ $labels.pod }}` in namespace `{{ $labels.namespace }}` on container `{{ $labels.container}}` has been in waiting state for longer than 1 hour. (reason: `{{ $labels.reason }}`).
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontainerwaiting"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: Pod container waiting longer than 1 hour
        expr: |
          kube_pod_container_status_waiting_reason{reason!="CrashLoopBackOff", job="kube-state-metrics"} > 0
        for: "1h"
        labels:
          severity: warning

      - alert: KubeDaemonSetNotScheduled
        annotations:
          description: >
            `{{ $value }}` Pods of DaemonSet `{{ $labels.namespace }}`/`{{ $labels.daemonset }}` are not scheduled.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: DaemonSet pods are not scheduled.
        expr: |
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
            -
          kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
        for: "10m"
        labels:
          severity: warning

      - alert: KubeDaemonSetMisScheduled
        annotations:
          description: >
            `{{ $value }}` Pods of DaemonSet `{{ $labels.namespace }}`/`{{ $labels.daemonset }}` are running where they are not supposed to run.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: DaemonSet pods are misscheduled.
        expr: |
          kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
        for: "15m"
        labels:
          severity: warning

      - alert: KubeJobNotCompleted
        annotations:
          description: >
            Job `{{ $labels.namespace }}`/`{{ $labels.job_name }}` is taking more than `{{ 43200 | humanizeDuration }}` to complete.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobnotcompleted"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: Job did not complete in time
        expr: |
          time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics"}
            and
          kube_job_status_active{job="kube-state-metrics"} > 0) > 43200
        labels:
          severity: warning

      - alert: KubeJobFailed
        annotations:
          description: >
            Job `{{ $labels.namespace }}`/`{{ $labels.job_name }}` failed to complete. Removing failed job after investigation should clear this alert.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: Job failed to complete.
        expr: |
          kube_job_failed{job="kube-state-metrics"}  > 0
        for: "15m"
        labels:
          severity: warning

      - alert: KubeHpaReplicasMismatch
        annotations:
          description: >
            HPA `{{ $labels.namespace }}`/`{{ $labels.horizontalpodautoscaler  }}` has not matched the desired number of replicas for longer than `15 minutes`.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpareplicasmismatch"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: HPA has not matched desired number of replicas.
        expr: |
          (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics"}
            !=
          kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"})
            and
          (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
            >
          kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics"})
            and
          (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
            <
          kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"})
            and
          changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}[15m]) == 0
        for: "15m"
        labels:
          severity: warning

      - alert: KubeHpaMaxedOut
        annotations:
          description: >
            HPA `{{ $labels.namespace }}`/`{{ $labels.horizontalpodautoscaler  }}` has been running at max replicas for longer than 15 minutes.
          runbook_url: "https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpamaxedout"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          sumary: HPA is running at max replicas
        expr: |
          kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
            ==
          kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}
        for: "15m"
        labels:
          severity: warning

      - alert: KubeHostOomKillDetected
        expr: increase(node_vmstat_oom_kill{job="node-exporter"}[5m]) > 0
        for: 5m
        labels:
          severity: critical
          robusta_incidentio_severity: minor
        annotations:
          summary: OOMkill was detected on the Node instance `{{ $labels.instance }}`
          description: >
            OOMkill on the instance `{{ $labels.instance }}` was detected in the past `5 minutes`.
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"
          runbook_url: https://runbook.mailergroup.com/HostNearlyOutOfMemory

      - alert: KubeStatefulsetDown
        expr: (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas) != 1
        for: 5m
        labels:
          severity: critical
          robusta_incidentio_severity: major
        annotations:
          summary: "Kubernetes StatefulSet `{{ $labels.statefulset }}` is down"
          description: >
            `{{ $labels.statefulset }}` StatefulSet in namespace `{{ $labels.namespace }}` is down for the past `5 minutes`.
          runbook_url: "https://runbook.mailergroup.com/KubernetesStatefulsetDown"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"

      - alert: KubeHpaScalingAbility
        expr: kube_horizontalpodautoscaler_status_condition{status="false", condition ="AbleToScale"} == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Kubernetes HPA scaling ability lost"
          description: >
            `{{ $labels.horizontalpodautoscaler }}` HPA has lost the ability to scale pods on `{{ $labels.cluster }}` cluster.
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"

      - alert: KubeHpaMetricAvailability
        expr: kube_horizontalpodautoscaler_status_condition{status="false", condition="ScalingActive", horizontalpodautoscaler != "keda-hpa-dummy-workload"} == 1
        for: 5m
        labels:
          severity: critical
          robusta_incidentio_severity: minor
        annotations:
          summary: "Kubernetes HPA metric availability"
          description: >
            `{{ $labels.horizontalpodautoscaler }}` HPA is not able to collect metrics on `{{ $labels.cluster }}` cluster.
          runbook_url: "https://runbook.mailergroup.com/KubernetesHpaMetricAvailability"
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods"

      - alert: KubeHighTcpRetransmitRate
        expr: sum by (instance, cluster) (rate(node_netstat_Tcp_RetransSegs{instance=~"10.*"}[15m]) / rate(node_netstat_Tcp_OutSegs{instance=~"10.*"}[15m])) > 0.1
        labels:
          severity: warning
        annotations:
          summary: "High TCP retransmit rate detected"
          description: >
            The instance `{{ $labels.instance }}` in the `{{ $labels.cluster }}` cluster is experiencing a high rate of TCP retransmissions of `{{ $value | printf "%.2f"}}%`, with a ratio exceeding `10%` over the last `10 minutes`. High values indicate potential network issues or congestion affecting TCP connections that should be immediately checked.
          dashboard_url: "{{ $labels.grafana_url }}/d/k8s-networking-ingress/kubernetes-networking-ingress"
