apiVersion: operator.victoriametrics.com/v1beta1
kind: VMRule
metadata:
  name: kubernetes-apps-rules
  namespace: monitoring
spec:
  "groups":
  - "name": |-
      kubernetes.apps.rules
    "rules":
    - "alert": |-
        KubePodCrashLooping
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          Pod `{{ $labels.namespace }}`/`{{ $labels.pod }}` (`{{ $labels.container }}`) is in waiting state (reason: "CrashLoopBackOff").
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
        "summary": |-
          Pod is crash looping.
      "expr": |
        max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
      "for": |-
        5m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubePodCrashLooping
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          Pod `{{ $labels.namespace }}`/`{{ $labels.pod }}` (`{{ $labels.container }}`) is in waiting state (reason: "CrashLoopBackOff").
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
        "summary": |-
          Pod is crash looping.
      "expr": |
        max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
      "for": |-
        10m
      "labels":
        "severity": |-
          critical
    - "alert": |-
        KubePodNotReady
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          Pod `{{ $labels.namespace }}`/`{{ $labels.pod }}` has been in a non-ready state for longer than 15 minutes.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready
        "summary": |-
          Pod has been in a non-ready state for more than 15 minutes.
      "expr": |
        sum by (namespace, pod, cluster) (
          max by(namespace, pod, cluster) (
            kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown|Failed"}
          ) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (
            1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
          )
        ) > 0
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeDeploymentGenerationMismatch
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          Deployment generation for `{{ $labels.namespace }}`/`{{ $labels.deployment }}` does not match, this indicates that the Deployment has failed but has not been rolled back.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch
        "summary": |-
          Deployment generation mismatch due to possible roll-back
      "expr": |
        kube_deployment_status_observed_generation{job="kube-state-metrics"}
          !=
        kube_deployment_metadata_generation{job="kube-state-metrics"}
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeDeploymentReplicasMismatch
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          Deployment `{{ $labels.namespace }}`/`{{ $labels.deployment }}` has not matched the expected number of replicas for longer than 15 minutes.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch
        "summary": |-
          Deployment has not matched the expected number of replicas.
      "expr": |
        (
          kube_deployment_spec_replicas{job="kube-state-metrics"}
            >
          kube_deployment_status_replicas_available{job="kube-state-metrics"}
        ) and (
          changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[10m])
            ==
          0
        )
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeDeploymentRolloutStuck
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          Rollout of deployment `{{ $labels.namespace }}`/`{{ $labels.deployment }}` is not progressing for longer than 15 minutes.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentrolloutstuck
        "sumary": |-
          Deployment rollout is not progressing.
      "expr": |
        kube_deployment_status_condition{condition="Progressing", status="false",job="kube-state-metrics"}
        != 0
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeStatefulSetReplicasMismatch
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          StatefulSet `{{ $labels.namespace }}`/`{{ $labels.statefulset }}` has not matched the expected number of replicas for longer than 15 minutes.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch
        "sumary": |-
          StatefulSet has not matched the expected number of replicas.
      "expr": |
        (
          kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
            !=
          kube_statefulset_status_replicas{job="kube-state-metrics"}
        ) and (
          changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[10m])
            ==
          0
        )
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeStatefulSetGenerationMismatch
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          StatefulSet generation for `{{ $labels.namespace }}`/`{{ $labels.statefulset }}` does not match, this indicates that the StatefulSet has failed but has not been rolled back.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch
        "sumary": |-
          StatefulSet generation mismatch due to possible roll-back
      "expr": |
        kube_statefulset_status_observed_generation{job="kube-state-metrics"}
          !=
        kube_statefulset_metadata_generation{job="kube-state-metrics"}
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeStatefulSetUpdateNotRolledOut
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          StatefulSet `{{ $labels.namespace }}`/`{{ $labels.statefulset }}` update has not been rolled out.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout
        "sumary": |-
          StatefulSet update has not been rolled out.
      "expr": |
        (
          max by(namespace, statefulset, job, cluster) (
            kube_statefulset_status_current_revision{job="kube-state-metrics"}
              unless
            kube_statefulset_status_update_revision{job="kube-state-metrics"}
          )
            *
          (
            kube_statefulset_replicas{job="kube-state-metrics"}
              !=
            kube_statefulset_status_replicas_updated{job="kube-state-metrics"}
          )
        )  and (
          changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m])
            ==
          0
        )
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeDaemonSetRolloutStuck
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          DaemonSet `{{ $labels.namespace }}`/`{{ $labels.daemonset }}` has not finished or progressed for at least 15m.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck
        "sumary": |-
          DaemonSet rollout is stuck.
      "expr": |
        (
          (
            kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"}
            !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
          ) or (
            kube_daemonset_status_number_misscheduled{job="kube-state-metrics"}
            !=
            0
          ) or (
            kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}
            !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
          ) or (
            kube_daemonset_status_number_available{job="kube-state-metrics"}
            !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
          )
        ) and (
          changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}[5m])
            ==
          0
        )
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeContainerWaiting
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          `pod/{{ $labels.pod }}` in namespace `{{ $labels.namespace }}` on container `{{ $labels.container}}` has been in waiting state for longer than 1 hour. (reason: `{{ $labels.reason }}`).
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontainerwaiting
        "sumary": |-
          Pod container waiting longer than 1 hour
      "expr": |
        kube_pod_container_status_waiting_reason{reason!="CrashLoopBackOff", job="kube-state-metrics"} > 0
      "for": |-
        1h
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeDaemonSetNotScheduled
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          `{{ $value }}` Pods of DaemonSet `{{ $labels.namespace }}`/`{{ $labels.daemonset }}` are not scheduled.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled
        "sumary": |-
          DaemonSet pods are not scheduled.
      "expr": |
        kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}
          -
        kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
      "for": |-
        10m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeDaemonSetMisScheduled
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          `{{ $value }}` Pods of DaemonSet `{{ $labels.namespace }}`/`{{ $labels.daemonset }}` are running where they are not supposed to run.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled
        "sumary": |-
          DaemonSet pods are misscheduled.
      "expr": |
        kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeJobNotCompleted
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          Job `{{ $labels.namespace }}`/`{{ $labels.job_name }}` is taking more than `{{ 43200 | humanizeDuration }}` to complete.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobnotcompleted
        "sumary": |-
          Job did not complete in time
      "expr": |
        time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics"}
          and
        kube_job_status_active{job="kube-state-metrics"} > 0) > 43200
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeJobFailed
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          Job `{{ $labels.namespace }}`/`{{ $labels.job_name }}` failed to complete. Removing failed job after investigation should clear this alert.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed
        "sumary": |-
          Job failed to complete.
      "expr": |
        kube_job_failed{job="kube-state-metrics"}  > 0
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeHpaReplicasMismatch
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          HPA `{{ $labels.namespace }}`/`{{ $labels.horizontalpodautoscaler  }}` has not matched the desired number of replicas for longer than `15 minutes`.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpareplicasmismatch
        "sumary": |-
          HPA has not matched desired number of replicas.
      "expr": |
        (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics"}
          !=
        kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"})
          and
        (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
          >
        kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics"})
          and
        (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
          <
        kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"})
          and
        changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}[15m]) == 0
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeHpaMaxedOut
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          HPA `{{ $labels.namespace }}`/`{{ $labels.horizontalpodautoscaler  }}` has been running at max replicas for longer than 15 minutes.
        "runbook_url": |-
          https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpamaxedout
        "sumary": |-
          HPA is running at max replicas
      "expr": |
        kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
          ==
        kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}
      "for": |-
        15m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeHostOomKillDetected
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          OOMkill on the instance `{{ $labels.instance }}` was detected in the past `5 minutes`.
        "runbook_url": |-
          https://runbook.mailergroup.com/HostNearlyOutOfMemory
        "summary": |-
          OOMkill was detected on the Node instance `{{ $labels.instance }}`
      "expr": |-
        increase(node_vmstat_oom_kill{job="node-exporter"}[5m]) > 0
      "for": |-
        5m
      "labels":
        "robusta_incidentio_severity": |-
          minor
        "severity": |-
          critical
    - "alert": |-
        KubeStatefulsetDown
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          `{{ $labels.statefulset }}` StatefulSet in namespace `{{ $labels.namespace }}` is down for the past `5 minutes`.
        "runbook_url": |-
          https://runbook.mailergroup.com/KubernetesStatefulsetDown
        "summary": |-
          Kubernetes StatefulSet `{{ $labels.statefulset }}` is down
      "expr": |-
        (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas) != 1
      "for": |-
        5m
      "labels":
        "robusta_incidentio_severity": |-
          major
        "severity": |-
          critical
    - "alert": |-
        KubeHpaScalingAbility
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          `{{ $labels.horizontalpodautoscaler }}` HPA has lost the ability to scale pods on `{{ $labels.cluster }}` cluster.
        "summary": |-
          Kubernetes HPA scaling ability lost
      "expr": |-
        kube_horizontalpodautoscaler_status_condition{status="false", condition ="AbleToScale"} == 1
      "for": |-
        5m
      "labels":
        "severity": |-
          warning
    - "alert": |-
        KubeHpaMetricAvailability
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-views-pods/kubernetes-views-pods
        "description": |
          `{{ $labels.horizontalpodautoscaler }}` HPA is not able to collect metrics on `{{ $labels.cluster }}` cluster.
        "runbook_url": |-
          https://runbook.mailergroup.com/KubernetesHpaMetricAvailability
        "summary": |-
          Kubernetes HPA metric availability
      "expr": |-
        kube_horizontalpodautoscaler_status_condition{status="false", condition="ScalingActive", horizontalpodautoscaler != "keda-hpa-dummy-workload"} == 1
      "for": |-
        5m
      "labels":
        "robusta_incidentio_severity": |-
          minor
        "severity": |-
          critical
    - "alert": |-
        KubeHighTcpRetransmitRate
      "annotations":
        "dashboard_url": |-
          {{ $labels.grafana_url }}/d/k8s-networking-ingress/kubernetes-networking-ingress
        "description": |
          The instance `{{ $labels.instance }}` in the `{{ $labels.cluster }}` cluster is experiencing a high rate of TCP retransmissions of `{{ $value | printf "%.2f"}}%`, with a ratio exceeding `10%` over the last `10 minutes`. High values indicate potential network issues or congestion affecting TCP connections that should be immediately checked.
        "summary": |-
          High TCP retransmit rate detected
      "expr": |-
        sum by (instance, cluster) (rate(node_netstat_Tcp_RetransSegs{instance=~"10.*"}[15m]) / rate(node_netstat_Tcp_OutSegs{instance=~"10.*"}[15m])) > 0.1
      "labels":
        "severity": |-
          warning
